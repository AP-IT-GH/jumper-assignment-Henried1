{
    "name": "root",
    "gauges": {
        "CubeAgent.Policy.Entropy.mean": {
            "value": 1.3175595998764038,
            "min": 1.3174974918365479,
            "max": 1.3175595998764038,
            "count": 3
        },
        "CubeAgent.Policy.Entropy.sum": {
            "value": 2614.038330078125,
            "min": 2057.96826171875,
            "max": 2660.02734375,
            "count": 3
        },
        "CubeAgent.Environment.EpisodeLength.mean": {
            "value": 70.0,
            "min": 70.0,
            "max": 88.625,
            "count": 2
        },
        "CubeAgent.Environment.EpisodeLength.sum": {
            "value": 350.0,
            "min": 350.0,
            "max": 1418.0,
            "count": 2
        },
        "CubeAgent.Step.mean": {
            "value": 99952.0,
            "min": 95949.0,
            "max": 99952.0,
            "count": 3
        },
        "CubeAgent.Step.sum": {
            "value": 99952.0,
            "min": 95949.0,
            "max": 99952.0,
            "count": 3
        },
        "CubeAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.009448849596083164,
            "min": 0.009448849596083164,
            "max": 0.2199648916721344,
            "count": 3
        },
        "CubeAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 0.29291433095932007,
            "min": 0.29291433095932007,
            "max": 7.478806495666504,
            "count": 3
        },
        "CubeAgent.Environment.CumulativeReward.mean": {
            "value": 0.3199999988079071,
            "min": 0.3199999988079071,
            "max": 0.47500000055879354,
            "count": 2
        },
        "CubeAgent.Environment.CumulativeReward.sum": {
            "value": 1.5999999940395355,
            "min": 1.5999999940395355,
            "max": 7.600000008940697,
            "count": 2
        },
        "CubeAgent.Policy.ExtrinsicReward.mean": {
            "value": 0.3199999988079071,
            "min": 0.3199999988079071,
            "max": 0.47500000055879354,
            "count": 2
        },
        "CubeAgent.Policy.ExtrinsicReward.sum": {
            "value": 1.5999999940395355,
            "min": 1.5999999940395355,
            "max": 7.600000008940697,
            "count": 2
        },
        "CubeAgent.Losses.PolicyLoss.mean": {
            "value": 0.23798388282569552,
            "min": 0.23676969543274834,
            "max": 0.2479387491352723,
            "count": 3
        },
        "CubeAgent.Losses.PolicyLoss.sum": {
            "value": 3.569758242385433,
            "min": 2.7273262404879954,
            "max": 3.7883151269239734,
            "count": 3
        },
        "CubeAgent.Losses.ValueLoss.mean": {
            "value": 8.335294646123524e-05,
            "min": 8.335294646123524e-05,
            "max": 0.011686240429012078,
            "count": 3
        },
        "CubeAgent.Losses.ValueLoss.sum": {
            "value": 0.0012502941969185287,
            "min": 0.0012502941969185287,
            "max": 0.12854864471913285,
            "count": 3
        },
        "CubeAgent.Policy.LearningRate.mean": {
            "value": 3.0240989919999997e-06,
            "min": 3.0240989919999997e-06,
            "max": 1.4255277066454547e-05,
            "count": 3
        },
        "CubeAgent.Policy.LearningRate.sum": {
            "value": 4.536148488e-05,
            "min": 4.536148488e-05,
            "max": 0.000156808047731,
            "count": 3
        },
        "CubeAgent.Policy.Epsilon.mean": {
            "value": 0.101008,
            "min": 0.101008,
            "max": 0.10475172727272729,
            "count": 3
        },
        "CubeAgent.Policy.Epsilon.sum": {
            "value": 1.51512,
            "min": 1.1522690000000002,
            "max": 1.6479370000000002,
            "count": 3
        },
        "CubeAgent.Policy.Beta.mean": {
            "value": 0.0005000000000000002,
            "min": 0.0005,
            "max": 0.0005000000000000002,
            "count": 3
        },
        "CubeAgent.Policy.Beta.sum": {
            "value": 0.007500000000000003,
            "min": 0.005500000000000001,
            "max": 0.008,
            "count": 3
        },
        "CubeAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        },
        "CubeAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1713557299",
        "python_version": "3.9.19 (main, Mar 21 2024, 17:21:27) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\henry\\anaconda3\\envs\\agent2\\Scripts\\mlagents-learn config/CubeAgent.yaml --run-id=CubeAgent --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1713557480"
    },
    "total": 181.6522085,
    "count": 1,
    "self": 0.018004900000022417,
    "children": {
        "run_training.setup": {
            "total": 0.24213869999999993,
            "count": 1,
            "self": 0.24213869999999993
        },
        "TrainerController.start_learning": {
            "total": 181.39206489999998,
            "count": 1,
            "self": 0.21071480000057363,
            "children": {
                "TrainerController._reset_env": {
                    "total": 16.954973000000003,
                    "count": 1,
                    "self": 16.954973000000003
                },
                "TrainerController.advance": {
                    "total": 164.00522449999943,
                    "count": 5585,
                    "self": 0.21828219999832754,
                    "children": {
                        "env_step": {
                            "total": 117.71908280000113,
                            "count": 5585,
                            "self": 68.4748210000022,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 49.111958200000075,
                                    "count": 5585,
                                    "self": 0.7130523999997536,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 48.39890580000032,
                                            "count": 5565,
                                            "self": 48.39890580000032
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.13230359999885977,
                                    "count": 5585,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 167.9015062,
                                            "count": 5585,
                                            "is_parallel": true,
                                            "self": 108.95912140000013,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0005049000000010295,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00031389999999831275,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00019100000000271677,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00019100000000271677
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 58.941879899999876,
                                                    "count": 5585,
                                                    "is_parallel": true,
                                                    "self": 0.7683194000017863,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 0.7141722999982356,
                                                            "count": 5585,
                                                            "is_parallel": true,
                                                            "self": 0.7141722999982356
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 55.06130380000039,
                                                            "count": 5585,
                                                            "is_parallel": true,
                                                            "self": 55.06130380000039
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 2.3980843999994654,
                                                            "count": 5585,
                                                            "is_parallel": true,
                                                            "self": 1.52480679999897,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.8732776000004954,
                                                                    "count": 11170,
                                                                    "is_parallel": true,
                                                                    "self": 0.8732776000004954
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 46.067859499999955,
                            "count": 5585,
                            "self": 0.26227999999996143,
                            "children": {
                                "process_trajectory": {
                                    "total": 1.109925700000094,
                                    "count": 5585,
                                    "self": 1.109925700000094
                                },
                                "_update_policy": {
                                    "total": 44.6956537999999,
                                    "count": 42,
                                    "self": 1.7150831000005553,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 42.98057069999935,
                                            "count": 1542,
                                            "self": 42.98057069999935
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.9999999949504854e-06,
                    "count": 1,
                    "self": 1.9999999949504854e-06
                },
                "TrainerController._save_models": {
                    "total": 0.2211505999999872,
                    "count": 1,
                    "self": 0.02085349999998698,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.20029710000000023,
                            "count": 1,
                            "self": 0.20029710000000023
                        }
                    }
                }
            }
        }
    }
}